{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "import numpy as np\n",
    "import math \n",
    "import pandas as pd\n",
    "import pickle \n",
    "\n",
    "def pre_processing(train_file_names):\n",
    "    '''Initial Pre Processing'''\n",
    "    for i in train_file_names:\n",
    "        Train=(pickle.load(open(i,'rb'))).T\n",
    "        Train.index.name='Book'\n",
    "        r,n=Train.shape\n",
    "        col_mean=np.matrix(Train.mean())       \n",
    "        Train_col=Train.values-col_mean \n",
    "        '''Subtract Column mean from respective columns'''\n",
    "        row_mean=np.matrix(Train.mean(axis=1))\n",
    "        Train_processed=Train_col-row_mean.T\n",
    "        '''Subtract Row mean from resulting matrix'''\n",
    "        new_data=pd.DataFrame(Train_processed, columns=Train.columns)\n",
    "        new_data.set_index(Train.index,inplace=True)\n",
    "        new_data.to_pickle(i+'kl')                              \n",
    "        pd.DataFrame(col_mean).to_pickle('Column_mean_'+i+'kl')        \n",
    "        '''Save Column mean for denormalization'''\n",
    "        pd.DataFrame(row_mean).to_pickle('Row_mean_'+i+'kl') \n",
    "        '''Save Row mean for denormalization'''\n",
    "        del new_data\n",
    "        \n",
    "        \n",
    "def stochastic_descent(U,P,indices,mu,la,M_orig,max_iter):\n",
    "    '''Performs Stochastic Gradient Descent and Returns \n",
    "    Optimized Matrices'''\n",
    "    total_cost=[]  \n",
    "    '''total cost after complete one iteration'''\n",
    "    ''' prev_cost=[]  cost function at every observation before updating new values of U and P for one iteration''' \n",
    "    '''new_cost=[]   cost function at every observation after updating new values of U and P for one iteration '''\n",
    "    \n",
    "    err=0\n",
    "    err_new=0\n",
    "\n",
    "\n",
    "    for x in range(max_iter):\n",
    "        for i,j in indices:\n",
    "            err=2*(M_orig[i,j]-(U[i,:]*P[:,j]))\n",
    "            '''prev_cost.append(np.square(err/2)[0,0]+la*(np.sum(np.square(P[:,j]))+np.sum(np.square(U[i,:])))) '''\n",
    "            U_temp=U[i,:]+mu*((err[0,0]*P[:,j].T)-(la*U[i,:]))\n",
    "            P_temp=P[:,j]+mu*(err[0,0]*U[i,:].T-la*P[:,j])\n",
    "            U[i,:]=U_temp\n",
    "            P[:,j]=P_temp\n",
    "            ''' err_new=2*(M_orig[i,j]-(U[i,:]*P[:,j]))'''\n",
    "            \n",
    "            '''new_cost.append(np.square(err_new/2)[0,0]+la*(np.sum(np.square(P[:,j]))+np.sum(np.square(U[i,:])))) #cost function at every observation after updating new values of U and P for one iteration '''        \n",
    "        error=0\n",
    "        P_sum=0\n",
    "        U_sum=0\n",
    "        for i,j in indices:\n",
    "            error=error+np.square((M_orig[i,j]-(U[i,:]*P[:,j])))\n",
    "            P_sum=P_sum+np.sum(np.square(P[:,j]))\n",
    "            U_sum=U_sum+np.sum(np.square(U[i,:]))\n",
    "        \n",
    "        error=error+la*(P_sum+U_sum)\n",
    "        total_cost.append(error[0,0])\n",
    "    \n",
    "    return U,P,total_cost\n",
    "\n",
    "\n",
    "def gen_predictions(Preds,Row_mean,Col_mean,Ratings_index,Ratings_columns):\n",
    "    '''Returns De Normalized Predictions'''\n",
    "    Preds=Preds.values\n",
    "    Row_mean=Row_mean.values\n",
    "    Col_mean=Col_mean.values\n",
    "    final_preds=Preds+Row_mean.T+Col_mean                                       #Denormalize the predicted matrix\n",
    "    Final_predictions=pd.DataFrame(final_preds,index=Ratings_index, columns=Ratings_columns)\n",
    "    return Final_predictions\n",
    "\n",
    "\n",
    "def gen_ISBN(Final_predictions,indices,Ratings_index,Ratings_columns):\n",
    "    '''Generates Sorted ISBN Based on Estimated Predictions'''\n",
    "    Sorted_Predictions=Final_predictions.values\n",
    "    Sorted_Predictions[indices[:,0],indices[:,1]]=-float('inf')\n",
    "    Sorted_Predictions=pd.DataFrame(Sorted_Predictions,index=Final_predictions.index, columns=Final_predictions.columns)\n",
    "    \n",
    "    Book_ISBN=pd.DataFrame()\n",
    "    for i in Sorted_Predictions.columns:\n",
    "        data=pd.DataFrame(Sorted_Predictions.sort_values(i,ascending=False).index)\n",
    "        Book_ISBN=Book_ISBN.append([data.T])\n",
    "    \n",
    "    Book_ISBN.set_index(Ratings_columns, inplace=True)\n",
    "    \n",
    "    return(Book_ISBN)\n",
    "\n",
    "\n",
    "\n",
    "def gen_final_recommendations(Final_predictions,indices):\n",
    "    '''Generates Sorted Predictions'''\n",
    "    Sorted_Predictions=Final_predictions.values\n",
    "    Sorted_Predictions[indices[:,0],indices[:,1]]=-float('inf')\n",
    "    Sorted_Predictions=pd.DataFrame(Sorted_Predictions,index=Final_predictions.index, columns=Final_predictions.columns)\n",
    "    #Sort the dataframe\n",
    "    Sorted_preds_df=pd.DataFrame([Sorted_Predictions[col].order(ascending = False).reset_index(drop=True) for col in Sorted_Predictions])\n",
    "    #Map ratings between 0 to 10\n",
    "    indices_inf=np.argwhere(np.isinf(Sorted_preds_df.values)==True)\n",
    "    Sorted_preds_df.iloc[indices_inf[:,0],indices_inf[:,1]]=0\n",
    "    Sorted_preds_df=((Sorted_preds_df-np.min(np.min(Sorted_preds_df)))/(np.max(np.max(Sorted_preds_df))-np.min(np.min(Sorted_preds_df))))*10\n",
    "    Sorted_preds_df.iloc[indices_inf[:,0],indices_inf[:,1]]=-float('inf')\n",
    "    return Sorted_preds_df\n",
    "\n",
    "\n",
    "\n",
    "def gen_indices(Test0,Test1,Test2,Test3,Test4):\n",
    "    '''Generate indices to index nonzero values in Training and Test set '''\n",
    "    tmp0=np.transpose(np.nonzero(Test0.values))\n",
    "    Test0_indices=np.mat((Test0.index[tmp0[:,0]],Test0.columns[tmp0[:,1]])).T\n",
    "    tmp1=np.transpose(np.nonzero(Test1.values))\n",
    "    Test1_indices=np.mat((Test1.index[tmp1[:,0]],Test1.columns[tmp1[:,1]])).T\n",
    "    tmp2=np.transpose(np.nonzero(Test2.values))\n",
    "    Test2_indices=np.mat((Test2.index[tmp2[:,0]],Test2.columns[tmp2[:,1]])).T\n",
    "    tmp3=np.transpose(np.nonzero(Test3.values))\n",
    "    Test3_indices=np.mat((Test3.index[tmp3[:,0]],Test3.columns[tmp3[:,1]])).T\n",
    "    tmp4=np.transpose(np.nonzero(Test4.values))\n",
    "    Test4_indices=np.mat((Test4.index[tmp4[:,0]],Test4.columns[tmp4[:,1]])).T\n",
    "    return Test0_indices,Test1_indices,Test2_indices,Test3_indices,Test4_indices\n",
    "\n",
    "\n",
    "def mae(Train0,Train1,Train2,Train3,Train4,Test0,Test1,Test2,Test3,Test4):\n",
    "    '''Mean absolute error function '''\n",
    "    Test0_indices,Test1_indices,Test2_indices,Test3_indices,Test4_indices=gen_indices(Test0,Test1,Test2,Test3,Test4)\n",
    "    mae0=0\n",
    "    for i in Test0_indices:\n",
    "        x=np.ravel(i)\n",
    "        mae0=mae0+abs(Train0.loc[x[0],x[1]]-Test0.loc[x[0],x[1]])\n",
    "    mae0=(mae0/Test0_indices.shape[0])\n",
    "    mae1=0\n",
    "    for i in Test1_indices:\n",
    "        x=np.ravel(i)\n",
    "        mae1=mae1+abs(Train1.loc[x[0],x[1]]-Test1.loc[x[0],x[1]])\n",
    "    mae1=(mae1/Test1_indices.shape[0])\n",
    "    mae2=0\n",
    "    for i in Test2_indices:\n",
    "        x=np.ravel(i)\n",
    "        mae2=mae2+abs(Train2.loc[x[0],x[1]]-Test2.loc[x[0],x[1]])\n",
    "    mae2=(mae2/Test2_indices.shape[0])\n",
    "    mae3=0\n",
    "    for i in Test3_indices:\n",
    "        x=np.ravel(i)\n",
    "        mae3=mae3+abs(Train3.loc[x[0],x[1]]-Test3.loc[x[0],x[1]])\n",
    "    mae3=(mae3/Test3_indices.shape[0])\n",
    "    mae4=0\n",
    "    for i in Test4_indices:\n",
    "        x=np.ravel(i)\n",
    "        mae4=mae4+abs(Train4.loc[x[0],x[1]]-Test4.loc[x[0],x[1]])\n",
    "    mae4=(mae4/Test4_indices.shape[0])\n",
    "    return ((mae0+mae1+mae2+mae3+mae4)/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Pre-processing'''\n",
    "train_file_names=['Train0svd.p','Train1svd.p','Train2svd.p','Train3svd.p','Train4svd.p']\n",
    "pre_processing(train_file_names)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Load the Training Data into RAM'''\n",
    "Ratings=pickle.load(open('Train0svd.pkl','rb'))         #Pre processed matrix of ratings\n",
    "Ratings.index.name='Book'\n",
    "Ratings.fillna(0,inplace=True)\n",
    "\n",
    "'''SVD Matrix Initialization'''\n",
    "r,c=Ratings.shape\n",
    "k=100\n",
    "U=np.matrix(np.random.rand(r,k)*np.sqrt(5/k))\n",
    "P=np.matrix(np.random.rand(k,c)*np.sqrt(5/k))\n",
    "M_orig=Ratings.values\n",
    "indices=np.transpose(np.nonzero(M_orig))\n",
    "\n",
    "'''Stochastic Gradient Descent Running'''\n",
    "User,Items,t_cost=stochastic_descent(U,P,indices,0.003,0.2,M_orig,400)\n",
    "Preds=User*Items\n",
    "pd.DataFrame(Preds).to_pickle('Train0Predictions_0.003_0.2_400.pkl')\n",
    "\n",
    "Preds=pickle.load(open('Train4Predictions_0.003_0.2_400.pkl','rb'))\n",
    "Row_mean=pickle.load(open('Row_mean_Train4svd.pkl','rb'))\n",
    "Col_mean=pickle.load(open('Column_mean_Train4svd.pkl','rb'))\n",
    "Row_mean.fillna(0,inplace = True)\n",
    "Col_mean.fillna(0,inplace = True)\n",
    "\n",
    "'''Sorting ISBN '''\n",
    "Book_ISBN=gen_ISBN(Final_predictions,indices,Ratings.index,Ratings.columns)\n",
    "Book_ISBN.to_pickle('Train4Book_ISBN.pkl')\n",
    "\n",
    "Final_predictions=gen_predictions(Preds,Row_mean,Col_mean, Ratings.index,Ratings.columns)\n",
    "Final_predictions.to_pickle('Train4Final_Predictions.pkl') #unsorted\n",
    "\n",
    "Sorted_preds_df=gen_final_recommendations(Final_predictions,indices)\n",
    "Sorted_preds_df.to_pickle('Train4Final_Recommendations.pkl')\n",
    "\n",
    "\n",
    "del Ratings,Preds,Final_predictions,Book_ISBN,Sorted_preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34926944712212432"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Training files\n",
    "\n",
    "Train0=(pickle.load(open('Train0Final_Predictions.pkl','rb'))).T            #Train file 0\n",
    "Train0.fillna(0,inplace=True)\n",
    "Train1=(pickle.load(open('Train1Final_Predictions.pkl','rb'))).T            #Train file 1        \n",
    "Train1.fillna(0,inplace=True)\n",
    "Train2=(pickle.load(open('Train2Final_Predictions.pkl','rb'))).T            #Train file 2\n",
    "Train2.fillna(0,inplace=True)\n",
    "Train3=(pickle.load(open('Train3Final_Predictions.pkl','rb'))).T            #Train file 3\n",
    "Train3.fillna(0,inplace=True)\n",
    "Train4=(pickle.load(open('Train4Final_Predictions.pkl','rb'))).T            #Train file 4\n",
    "Train4.fillna(0,inplace=True)\n",
    "\n",
    "#Load Test files\n",
    "\n",
    "Test0=pickle.load(open('Test0svd.p','rb'))         \n",
    "Test0.fillna(0,inplace=True)\n",
    "Test1=pickle.load(open('Test1svd.p','rb'))         \n",
    "Test1.fillna(0,inplace=True)\n",
    "Test2=pickle.load(open('Test2svd.p','rb'))         \n",
    "Test2.fillna(0,inplace=True)\n",
    "Test3=pickle.load(open('Test3svd.p','rb'))         \n",
    "Test3.fillna(0,inplace=True)\n",
    "Test4=pickle.load(open('Test4svd.p','rb'))         \n",
    "Test4.fillna(0,inplace=True)\n",
    "mae_total=mae(Train0,Train1,Train2,Train3,Train4,Test0,Test1,Test2,Test3,Test4)\n",
    "mae_total/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddhant/python/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:99: FutureWarning: order is deprecated, use sort_values(...)\n"
     ]
    }
   ],
   "source": [
    "Ratings=pickle.load(open('Train4svd.pkl','rb'))         #Pre processed matrix of ratings\n",
    "Ratings.index.name='Book'\n",
    "Ratings.fillna(0,inplace=True)\n",
    "M_orig=Ratings.values\n",
    "indices=np.transpose(np.nonzero(M_orig))\n",
    "\n",
    "Preds=pickle.load(open('Train4Predictions_0.003_0.2_400.pkl','rb'))\n",
    "Row_mean=pickle.load(open('Row_mean_Train4svd.pkl','rb'))\n",
    "Col_mean=pickle.load(open('Column_mean_Train4svd.pkl','rb'))\n",
    "Row_mean.fillna(0,inplace = True)\n",
    "Col_mean.fillna(0,inplace = True)\n",
    "\n",
    "'''Sorting ISBN '''\n",
    "Book_ISBN=gen_ISBN(Final_predictions,indices,Ratings.index,Ratings.columns)\n",
    "Book_ISBN.to_pickle('Train4Book_ISBN.pkl')\n",
    "\n",
    "Final_predictions=gen_predictions(Preds,Row_mean,Col_mean, Ratings.index,Ratings.columns)\n",
    "Final_predictions.to_pickle('Train4Final_Predictions.pkl') #unsorted\n",
    "\n",
    "Sorted_preds_df=gen_final_recommendations(Final_predictions,indices)\n",
    "Sorted_preds_df.to_pickle('Train4Final_Recommendations.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
